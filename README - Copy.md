# Group-Lab-2-Destination-Data
For Group Lab 2 – Mapping Origin-Destination Data on Employment and Industry in the US. Advanced Digital Geographies 458

In this lab, we will start mapping in R. This will be the last R lab, so it will be a little bit longer, and you’ll have some additional time to complete it. We will cover static mapping, building off of the layer logic of ggplot, as well as interactive mapping. As always, however, much of your time will be spent getting the data itself to work, so plan accordingly!

The theme of this lab will be geographies of industry and employment in the United States. Exactly where you explore is up to you, the data you will be using is available everywhere in the nation (with a few minor exceptions). This lab will also familiarize you with the concept of “Origin-Destination” tables, which can be extremely useful tools in mapping, since they show the relationships between multiple geo-units. But they also tend to be large and unwieldy datasets, which is why managing them in something like R is ideal.

 

Part 1 – Preparation
For this lab, we will be using some data from the US Census’ “Longitudinal Employer-Household Dynamics (Links to an external site.)Links to an external site.” (LEHD) datasets. Specifically, we’ll be using the “LEHD Origin-Destination Employment Statistics” (LODES), which is a series of Origin-Destination Matrices and accompanying data that record block-to-block employment relationships. You’ll need to read the documentation here (Links to an external site.)Links to an external site.. But essentially there are three different types of LODES file.

The first is the “OD” data, which is the Origin-Destination matrix for a given year. This matrix records the employment relationship between a “home” census block and a “work” census block. I’ll use a simple example to illustrate what this means: let’s say you have four blocks, A, B, C, and D. A simple OD matrix here would have 9 entries, under the two variables homeblock and workblock, with variables sitting adjacent on the same row indicating an employment relationship: AA (i.e. people who live in A and work in A), AB (people who live in A and work in B), AC (etc…), BA, BB, BC, CA, CB,CC. The LODES “OD” files also include some information about the jobs that compose this relationship, including the total number of jobs (i.e. the total number of ppl living in A and working in B), some information on the income of the people working these jobs and basic sector information for them.

The second is “RAC” data, which is the Residence Area Characteristics. This is just block-level data that tells us about the jobs of people who live in block A. The sectoral breakdown is much more detailed.

The third is the “WAC” data, which is the Workplace Area Characteristics. This is block-level data that tells us about the jobs of people who work in block A—so this gives us more information about the firms operating in a location. The information is even more detailed here, including a sectoral breakdown, more demographic information, educational level of workers, firm size and firm age. 

An example of the difference between RAC and WAC: if you were to look at downtown or Southcenter, you’d see very small numbers in the RAC dataset, but very large numbers in the WAC dataset. That’s because these areas have lots of companies, but not as many people in residence.

In order to prepare your data you need to select a location to look at. You can do large areas or smaller areas (larger will take a little longer to map), but don’t get too small or you run into some problems with accuracy. Rural areas are fine, as are sections of larger cities, entire cities, greater metro areas, etc. You can also do entire states, but the borders will not be entirely accurate (see below), and we’ll ultimately be working with tracts, so loading times might be a bit long. The main goal here is to explore the character of employment in an area and produce a report on it, with accompanying maps.

**Also if you’re looking for a challenge, or a final project idea, feel free to try and do the entire country, you’ll have to write a loop (and/or a function) to automate the process of loading and merging data, and deal with the main/aux divide detailed below**

You have to choose a state, and then you’ll probably want to select the “main” OD file for that state, rather than the “aux” file. The “main” file is people whose residence and primary jobs are within that state, the “aux” file is people whose residence is outside the state but whose workplace is inside the state—this means that if you were doing an area along a state border, you may need to pull in some aux data from a neighboring state (this is harder, I’d suggest not choosing Vancouver, WA, for this reason, for example). You’ll also want to make sure it’s the JTOO file for “All Jobs.” To see more detail about what these all mean, refer to the documentation (Links to an external site.)Links to an external site..

Then you’ll also want the WAC and/or the RAC files for that state.

For all of this, choose the most recent year (probably 2015).

Hint: the file locations are something like this, for OD data in WA state in 2015: https://lehd.ces.census.gov/LODES7/wa/od/wa_od_main_JT00_2015.csv.gz (Links to an external site.)Links to an external site.

See if you can get R to load and unzip these automatically!

Finally, you are going to need your basic geographic shapefiles. These will depend a lot on exactly where you’re looking at, but we’re ultimately going to aggregate to Tract-level data. So you will want a shapefile of census tracts for your area. You may also want files for city/county borders, water bodies, etc. And if you choose to do your data processing via spatial joins, you may have to start with a shapefile of census blocks before aggregating it up. Many of these files might come with some built-in demographic data—that’s great, but try to find the closest possible year to match your LODES data!

A few options exist for obtaining these. You can of course just google something like “census tracts shapefile seattle” and see what you find. You can also try and use the official Census TIGER Shapefile website (Links to an external site.)Links to an external site.. For the Seattle area there are also tools like the shapefiles (Links to an external site.)Links to an external site. created/curated by the Puget Sound Regional Council. Similar resources can be found for other urban areas with a quick google search.

But you can also automate the download of these shapefiles in R! To get official Census TIGER files you can simply use the package (Links to an external site.)Links to an external site. “tigris”. Here (Links to an external site.)Links to an external site. is the detailed documentation. And here are a couple tutorials: a slideshow (Links to an external site.)Links to an external site., and a blog entry (Links to an external site.)Links to an external site.. Remember that to map you’ll want these in sf format, see here (Links to an external site.)Links to an external site. for a quick explanation of how to set this while using tigris.

Also note that some of these examples use the package (Links to an external site.)Links to an external site. “acs” to get access to American Community Survey data. You can use this as well, but you’ll need to get an API key here (Links to an external site.)Links to an external site.. An API (Links to an external site.)Links to an external site. is an “Application Programming Interface,” which basically just means a system through which your code can communicate with a different application located elsewhere, usually on a remote server. Think of it like a door to someone else’s server space. Like any other door, you might need to obtain a key, which allows the owner of that server some control over who comes and goes. This also means that APIs are marketized, and in some cases you have to pay for use. The ACS data, however, is free. Just apply for one and then use the code example here (Links to an external site.)Links to an external site. to apply it in R, using the command: api.key.install(key="YOUR API KEY")

Finaly, you might find the “tidycensus” package (Links to an external site.)Links to an external site. useful. See some examples of its use here (Links to an external site.)Links to an external site..

 

 

Part 2 –Data Processing
Once you get your data loaded into R, you’ll need to cut it down to just the blocks you want. You can do this with a spatial operation, or with a non-spatial data operation, it doesn’t really matter at this point—the only difference is whether you join the LODES data to shapefiles before or after. Note, however, that spatial operations won’t initially work on the OD data, since it will have multiple entries for blocks and then tracts. You’ll only spatialize the OD data after selecting out some tracts of interest!

Leave a copy of your data in its original form, at the block level, since you’ll be making a map of that first. But you’ll also want to aggregate it up to the Tract level, so that it’s easier to work with and matches additional data that you might want to add later. Don’t rush into this! For the OD data, you need to think about the logic of what you are trying to do. For example, you really don’t want to aggregate the entire dataset such that you have a single entry per worktract (or hometract), since this will either mess up the related tract or simply eliminate lots of relationships! That doesn’t make sense for OD data, since the unit of interest is the relationship between the two. So how do you aggregate up from block-to-block to tract-to-tract relationships, without elimination? Think of it like this: you will still want multiple entries for each tract, but you only want a single entry for each relationship between tracts. So aggregate all entries in which the worktract-hometract relationship is the same, rather than one or the other.

Here’s an example, in case you’re having trouble conceptualizing this: Let’s say the census tract code is something like A or B, while the census block code is something like A1 or B2, including the census tract code. So the block-to-block relationship might be something like A1-B2, A2-B2, A3-C1 and A4-C2. But when you strip out the block codes, the previous four relationships become A-B, A-B, A-C, and A-C. Notice the redundancy! You’ll want to combine the rows representing the A-B’s and the A-C’s into a single row, so you end up with A-B and A-C. You don’t want to combine all the A’s together, though, because then you either force the data into a format you don’t want yet (ending up with A-BC, for example) and/or you eliminate relationships entirely by breaking the data (accidentally summing B and C, which makes no logical sense).

This is not a problem for the WAC and RAC data, however, which you can aggregate as you would any other non-OD data, until you get a single entry per tract. You’ll want to again leave a block-level file accessible, but aggregate your WAC and/or RAC data up to tract as well.

Other than these conceptual hints, I’m not going to give you step-by-step instructions on how to do this, and there are many options. But I will provide you with an R script that does this sort of operation for the Seattle-Tacoma-Bellevue Metropolitan Statistical Area, located in the course files here (there are actually two, one for OD, one for WAC, in this folder). I wrote that script many years ago in Base R, in collaboration with another grad student in the department. It’s annotated, but it’s also very messy. First, note that this was prior to the advent of good mapping packages in R, so none of the manipulations are actually spatial. Second, you can see that we had two slightly different syntax styles, and it is not well designed to be automated or iterated, because I only needed the data this one time—but the most important thing is that it worked! This means that it should ultimately give you some insight into one way to do this—but note that tidyverse or spatial operations will likely be easier today. Also, you will want to read this documentation (Links to an external site.)Links to an external site. on how census block codes work. The method I used in the script above essentially just draws on the numeric logic of the block code to pull out the tract code and use it to aggregate the other data.

 

Part 3 – Visualizing and Mapping
You will be producing an html report that summarizes the employment composition of your chosen area, including the major tract-to-tract relationships. You have a lot of leeway with exactly what you produce here, and it will depend on the size/character of your area. There are only a few “checkboxes” I want you to make sure you cover:

First, this is a written report, so you need to narrate what you are showing throughout, and you should start with a summary that includes: a) as in Group Lab 1, you want to explain to the viewer where the data comes from, and some general problems with Census data (HINT: look at issues with “census microdata” and “interpolated values,” also for more general problems with how the census records things, look up “issues with Census race categories”), b) why the area is of interest, and c) a description of your main findings.

Second, begin with some (two or more) non-spatial visualizations to help understand your dataset. These can be at the block level or the tract level. But you can, for instance, visualize the OD block/tract relationships with the largest employment numbers, or the WAC/RAC blocks/tracts with the most jobs or workers. Histograms or barplots are probably the easiest way to do this, and they are a common way of looking at the distribution of your data. But you can also be creative—maybe plot some of the other variables against each other. Does high employment in manufacturing seem to correlate with large numbers of workers in particular income brackets? (NOTE: to do these comparisons, you will likely have to normalize by total jobs, meaning you need to create new “share” columns for all your rows)

Third, make some basic static maps. I want you to first map out all your block data, visualizing a variable of your choice at the block level. (NOTE: if you’re doing a whole state this may be too granular, and take too long to load, but give it a try anyways. If it doesn’t work, skip it). Next, I want you to map the same data at the tract level to get a good look at how the aggregation worked. For both of these simple visualizations, you’ll need to use the WAC or RAC files here, not the OD ones (which won’t join properly, since they should have multiple entries for tract). If you'd like to pair these static maps with some interactive counterparts you can do that as well, but you'll be making another version below.

Fourth, you need to now figure out a way to bring your OD data into a spatial form. What is the best way to do this? You’ll probably want to choose a few notable census tracts, either worktracts or hometracts. For each tract you’ve selected, you can make a subset of the data that includes just the tracts with which that worktract or hometract has a relationship. What does that look like? Let’s say I have one large census tract, or group of them, in an industrial area like the port of Seattle, and I want to see where all the workers who work in that area actually live. So you select a subset of your tract OD data (where worktract == that worktract or group of worktracts). You’ll end up with a lot of rows, all with the same worktract(s), but with different hometracts. Then to visualize this you can make two layers: one that shows the worktract(s) in question, highlighted in one color, and another that shows all the hometracts that send workers into that tract, highlighted in another color. You can do this in reverse too (i.e. let’s look at all the places where people who live in this one neighborhood work).

Fifth, visualize this last relationship on a map. You can choose either a static map, or an interactive one, whichever you feel best communicates your data given the geographies you are working with. **If you want a real challenge, though, teach yourself some flow-mapping and even non-spatial flow visualization techniques, you can see a few examples here (Links to an external site.)Links to an external site., here (Links to an external site.)Links to an external site. and here (Links to an external site.)Links to an external site.—NOTE that you can do this instead of the spatial analysis in part 6 if you’d prefer**

Sixth, I want you to perform at least one additional geocomputation, of your choosing. Make it an “analytic” one, not just for data-visualization purposes (i.e. not a spatial join that selects all points within one of your tracts). Aside from this, you can choose anything you want, so long as it makes sense, but here are a few ideas:

Calculate Location Quotients (Links to an external site.)Links to an external site. for all of your data, and then “zoom in” to look at the location quotients for the subset of tracts selected from your OD data. (HINT: here (Links to an external site.)Links to an external site.’s one way to do this in R)
Calculate a Local Moran’s I (Links to an external site.)Links to an external site. to find “clusters” of a particular variable (i.e. high employment in manufacturing, or high numbers of people in the lowest income brackets), then use that information as the criteria to select your subset of relationship data from the OD table. (HINT: there’s a tool (Links to an external site.)Links to an external site. in the spdep package that will do this, for a more detailed walktrhough see here (Links to an external site.)Links to an external site., but you may have to convert your data type)
Calculate a centroid for the downtown area of your city, and plot out the relationship between the some variable and distance from this centroid (this one won’t produce a map, that’s fine). (HINT: this is the method used in slides 26-28 here (Links to an external site.)Links to an external site.)
Add some other data of interest, maybe a points layer with the city’s top five employers’ facilities, and then look at some of the same distance relationships relative to these points. You could do a similar thing for lines, if you’re interested in proximity to transit, for instance. (HINT: it depends what distance relationship you want to look at, but output will likely be similar to option c above)
**This is a bit more intensive, but you can do the same process for a different area entirely and then compare the two results! Figure out a way to quantify this comparison, though, don’t just put two maps back to back—Location Quotients are one method, and you can even calculate a joint Location Quotient, or figure out a way to calculate a national-comparison Location Quotient**
**Instead of another spatial analysis, you could also challenge yourself with an advanced visualization technique instead: Use the OD data to teach yourself some flow-mapping and even non-spatial flow visualization techniques, you can see a few examples here (Links to an external site.)Links to an external site., here (Links to an external site.)Links to an external site. and here (Links to an external site.)Links to an external site.—NOTE I’ll accept both maps of flow and non-spatial visualizations, such as a Sankey Diagram (Links to an external site.)Links to an external site., but you need to make sure they are readable and not crazy messy, which may mean you want to perform them on a subset of the data**
 

Completion
As always, submit your html to canvas, and submit your rmd and html to your group github. Like in Group Lab 1, I want you to choose ONE person to submit the HTML to canvas (and a link to the group github repo containing the files as a comment). Everyone else in the group should submit the link to the github as a submission (i.e. not a comment), this way I can make sure that everyone has submitted/participated.  
